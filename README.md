# ğŸ”® Telco Customer Churn Prediction - MLOps Implementation

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.95+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ï¿½ Equipo de Desarrollo

**Universidad del Norte - Curso de Machine Learning**

- **Omar Medina** - AnÃ¡lisis y Modelado
- **AndrÃ©s EspaÃ±a** - MLOps e ImplementaciÃ³n

---

## ï¿½ğŸ“‹ DescripciÃ³n

Proyecto completo de **Machine Learning** y **MLOps** para predecir el abandono (churn) de clientes en una empresa de telecomunicaciones. Incluye anÃ¡lisis exploratorio, entrenamiento de modelos, interpretabilidad con LIME y despliegue con FastAPI y Docker.

### ğŸ¯ CaracterÃ­sticas Principales

- âœ… **AnÃ¡lisis Exploratorio de Datos (EDA)** completo
- âœ… **4 Modelos de ML**: Random Forest, XGBoost, CatBoost, LightGBM
- âœ… **OptimizaciÃ³n de hiperparÃ¡metros** con GridSearchCV
- âœ… **Interpretabilidad** con LIME
- âœ… **API REST** con FastAPI
- âœ… **ContainerizaciÃ³n** con Docker
- âœ… **CI/CD** con GitHub Actions
- âœ… **Tests unitarios** con pytest

---

## ğŸ“Š Dataset

**Telco Customer Churn** de Kaggle
- **TamaÃ±o**: ~7,000 registros
- **CaracterÃ­sticas**: 20 variables (demogrÃ¡ficas, servicios, facturaciÃ³n)
- **Variable objetivo**: Churn (Yes/No)
- **Tasa de churn**: ~27%

**Enlace**: [Telco Customer Churn Dataset](https://www.kaggle.com/blastchar/telco-customer-churn)

---

## ğŸ—ï¸ Estructura del Proyecto

```
Telco-Customer-Churn-Mlops/
â”œâ”€â”€ app/                           # Servicio FastAPI con el modelo
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                          # Datasets originales y limpios
â”œâ”€â”€ notebooks/                     # Notebooks originales (no modificar)
â”‚   â”œâ”€â”€ 1_eda_preprocessing.ipynb
â”‚   â”œâ”€â”€ 2_model_training.ipynb
â”‚   â””â”€â”€ 3_interpretability.ipynb
â”œâ”€â”€ jupyter-book/                  # DocumentaciÃ³n en Jupyter Book
â”‚   â”œâ”€â”€ intro.md
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ _config.yml
â”‚   â””â”€â”€ _toc.yml
â”œâ”€â”€ tests/                         # Pruebas automÃ¡ticas de la API
â”‚   â”œâ”€â”€ test_api_local.py
â”‚   â””â”€â”€ test_api_quick.py
â”œâ”€â”€ ejemplo_uso_api.py             # GuÃ­a rÃ¡pida para consumir la API
â”œâ”€â”€ requirements.txt               # Dependencias del proyecto
â”œâ”€â”€ Dockerfile                     # Imagen Docker lista para producciÃ³n
â”œâ”€â”€ .github/workflows/ci.yml       # Pipeline CI/CD en GitHub Actions
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Prerrequisitos

- Python 3.10+
- pip
- Docker (opcional, para containerizaciÃ³n)
- Git

### 1. Clonar el Repositorio

```bash
git clone https://github.com/MrSpain2104/Telco-Customer-Churn-Mlops.git
cd Telco-Customer-Churn-Mlops
```

### 2. Crear Entorno Virtual

```bash
# Windows (PowerShell)
python -m venv venv
.\venv\Scripts\Activate.ps1

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Ejecutar Notebooks

```bash
# Abrir Jupyter Notebook
jupyter notebook

# O usar VS Code con la extensiÃ³n de Jupyter
```

**Orden de ejecuciÃ³n:**
1. `1_eda_preprocessing.ipynb` â†’ AnÃ¡lisis y limpieza de datos
2. `2_model_training.ipynb` â†’ Entrenamiento de modelos
3. `3_interpretability.ipynb` â†’ Interpretabilidad con LIME

### 5. Ejecutar la API Localmente

```bash
# Desde el directorio raÃ­z
uvicorn app.api:app --reload --port 8000
```

La API estarÃ¡ disponible en:
- **AplicaciÃ³n**: http://localhost:8000
- **DocumentaciÃ³n interactiva**: http://localhost:8000/docs
- **DocumentaciÃ³n alternativa**: http://localhost:8000/redoc

---

## ğŸ³ Docker

### Construir la Imagen

```bash
docker build -t telco-churn-api .
```

### Ejecutar el Contenedor

```bash
# Crear y ejecutar (primera vez)
docker run -d --name telco-churn-container -p 8000:8000 telco-churn-api

# Detener
docker stop telco-churn-container

# Iniciar (despuÃ©s de creado)
docker start telco-churn-container

# Ver logs
docker logs telco-churn-container

# Eliminar contenedor
docker rm telco-churn-container
```

### Verificar Salud del Contenedor

```bash
curl http://localhost:8000/health
```

---

## ğŸ“¡ Uso de la API

### Endpoints Disponibles

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/` | InformaciÃ³n bÃ¡sica de la API |
| GET | `/health` | Estado de salud del servicio |
| POST | `/predict` | PredicciÃ³n individual de churn |
| POST | `/predict-batch` | PredicciÃ³n batch (mÃºltiples clientes) |
| GET | `/model-info` | InformaciÃ³n del modelo cargado |

### Ejemplo de PredicciÃ³n

#### Usando curl (PowerShell)

```powershell
curl -X POST http://localhost:8000/predict `
  -H "Content-Type: application/json" `
  -d '{
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 1,
    "PhoneService": "No",
    "MultipleLines": "No phone service",
    "InternetService": "DSL",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "No",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 29.85,
    "TotalCharges": 29.85
  }'
```

#### Respuesta Esperada

```json
{
  "churn_probability": 0.7854,
  "prediction": "Yes",
  "risk_level": "High",
  "confidence": 0.7854
}
```

#### Usando Python

```python
import requests

url = "http://localhost:8000/predict"

customer_data = {
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 1,
    "PhoneService": "No",
    "MultipleLines": "No phone service",
    "InternetService": "DSL",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "No",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 29.85,
    "TotalCharges": 29.85
}

response = requests.post(url, json=customer_data)
print(response.json())
```

---

## ğŸ§ª Tests

### Ejecutar Tests Unitarios

```bash
# Todos los tests
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=app --cov-report=html

# Ver reporte de cobertura
# Abrir htmlcov/index.html en el navegador
```

### Tests Incluidos

- âœ… Test de endpoints principales
- âœ… Test de validaciÃ³n de datos
- âœ… Test de respuestas de error
- âœ… Test de predicciÃ³n batch
- âœ… Test de categorizaciÃ³n de riesgo

---

## ğŸ“ˆ Resultados del Modelo

### MÃ©tricas de EvaluaciÃ³n

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Random Forest | 0.80 | 0.68 | 0.52 | 0.59 | 0.84 |
| XGBoost | 0.81 | 0.70 | 0.54 | 0.61 | 0.85 |
| CatBoost | 0.81 | 0.69 | 0.55 | 0.61 | 0.85 |
| LightGBM | 0.80 | 0.68 | 0.53 | 0.60 | 0.84 |

*Los valores exactos varÃ­an segÃºn la ejecuciÃ³n de GridSearchCV*

### Variables MÃ¡s Importantes

1. **tenure** (AntigÃ¼edad del cliente)
2. **Contract** (Tipo de contrato)
3. **MonthlyCharges** (Cargo mensual)
4. **TotalCharges** (Cargos totales)
5. **PaymentMethod** (MÃ©todo de pago)

---

## ğŸ” Insights de Negocio

### Factores de Alto Riesgo de Churn

- ğŸ”´ Contrato mes-a-mes (42% churn rate)
- ğŸ”´ Clientes nuevos (tenure < 12 meses)
- ğŸ”´ Pago con cheque electrÃ³nico (45% churn rate)
- ğŸ”´ Sin servicios adicionales (OnlineSecurity, TechSupport)
- ğŸ”´ Cargos mensuales altos (> $70)

### Recomendaciones de RetenciÃ³n

1. **Incentivar contratos de largo plazo** â†’ ReducciÃ³n estimada de churn: 30%
2. **Promover pagos automÃ¡ticos** â†’ ReducciÃ³n estimada de churn: 15%
3. **Ofrecer servicios adicionales gratuitos** (3-6 meses) â†’ Aumenta retenciÃ³n
4. **Programa de onboarding** para nuevos clientes
5. **RevisiÃ³n de precios** para clientes de alto valor

---

## ğŸ”„ CI/CD Pipeline

### GitHub Actions

El proyecto incluye un pipeline automatizado que:

1. âœ… **Lint**: Verifica calidad del cÃ³digo con Flake8
2. âœ… **Test**: Ejecuta tests unitarios con pytest
3. âœ… **Build**: Construye imagen Docker
4. âœ… **Test Container**: Verifica que el contenedor funcione
5. âœ… **Deploy**: Placeholder para despliegue a producciÃ³n

### ConfiguraciÃ³n

Para usar el pipeline en tu repositorio:

1. Fork o clona el proyecto
2. Configura secrets en GitHub (si usas Docker Hub):
   - `DOCKER_USERNAME`
   - `DOCKER_PASSWORD`
3. Haz push a la rama `main` o crea un pull request

---

## ï¿½ DocumentaciÃ³n

La documentaciÃ³n completa del proyecto estÃ¡ empaquetada como un Jupyter Book.

- **Construir localmente:**

  ```bash
  pip install "jupyter-book<2.0"
  jupyter-book build jupyter-book
  ```

- **Resultado:** abrir `jupyter-book/_build/html/index.html` en el navegador.
- **GitHub Pages:** tras publicar el sitio, actualiza este README con el enlace pÃºblico.

---

## ï¿½ğŸ“Š Monitoreo (Recomendaciones)

### Deriva de Datos

Monitorear cambios en la distribuciÃ³n de:
- DistribuciÃ³n de tenure
- DistribuciÃ³n de MonthlyCharges
- ProporciÃ³n de tipos de contrato

### MÃ©tricas de ProducciÃ³n

- **Latencia** de predicciones (< 100ms objetivo)
- **Throughput** (predicciones por segundo)
- **Tasa de error** de la API
- **Disponibilidad** del servicio (99.9% objetivo)

### Herramientas Sugeridas

- **Prometheus + Grafana**: MÃ©tricas y dashboards
- **ELK Stack**: Logs centralizados
- **MLflow**: Tracking de experimentos
- **Evidently AI**: Monitoreo de deriva de datos

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Data Science & ML
- Python 3.10
- pandas, numpy
- scikit-learn
- XGBoost, CatBoost, LightGBM
- LIME

### API & Deployment
- FastAPI
- Uvicorn
- Pydantic
- Docker

### Visualization
- matplotlib
- seaborn

### Testing & CI/CD
- pytest
- Flake8
- GitHub Actions

---

## ğŸ“ To-Do List

- [ ] Implementar autenticaciÃ³n en la API (JWT)
- [ ] Agregar monitoreo con Prometheus
- [ ] Implementar versionado de modelos
- [ ] Agregar A/B testing de modelos
- [ ] Crear dashboard de mÃ©tricas en tiempo real
- [ ] Implementar reentrenamiento automÃ¡tico
- [ ] Agregar mÃ¡s tests (integraciÃ³n, carga)

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¥ Autores

**Universidad del Norte - Curso de Machine Learning**

- **Omar Medina** - AnÃ¡lisis y Modelado
- **AndrÃ©s EspaÃ±a** - MLOps e ImplementaciÃ³n

---

## ğŸ“§ Contacto

**Repositorio:** [GitHub - Telco Customer Churn MLOps](https://github.com/MrSpain2104/Telco-Customer-Churn-Mlops)

**Equipo:**
- Omar Medina
- AndrÃ©s EspaÃ±a

---

## ğŸ™ Agradecimientos

- Dataset de Kaggle: [Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)
- Comunidad de FastAPI
- Comunidad de scikit-learn
- Tutoriales y recursos de MLOps

---

## ğŸ“š Referencias

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [LIME: Local Interpretable Model-Agnostic Explanations](https://github.com/marcotcr/lime)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)

---

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!**

---

<div align="center">
  <p><strong>Universidad del Norte</strong></p>
  <p>Curso de Machine Learning</p>
  <p>2025</p>
</div>
